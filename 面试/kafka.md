**1、请说明什么是Apache Kafka?**
Apache Kafka是由Apache开发的一种发布订阅消息系统，它是一个分布式的、分区的和重复的日志服务。

**2、请说明什么是传统的消息传递方法?**

传统的消息传递方法包括两种：

排队：在队列中，一组用户可以从服务器中读取消息，每条消息都发送给其中一个人。
发布-订阅：在这个模型中，消息被广播给所有的用户。
**3、请说明Kafka相对传统技术有什么优势?**

Apache Kafka与传统的消息传递技术相比优势之处在于：

快速:单一的Kafka代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作。

可伸缩:在一组机器上对数据进行分区和简化，以支持更大的数据

持久:消息是持久性的，并在集群中进行复制，以防止数据丢失。

设计:它提供了容错保证和持久性

**4、在Kafka中broker的意义是什么?**

在Kafka集群中，broker术语用于引用服务器。

**5、Kafka服务器能接收到的最大信息是多少?**

Kafka服务器可以接收到的消息的最大大小由参数message.max.bytes决定，010版本默认值是1000012，可以配置为broker级别或者topic级别。

**6、解释Kafka的Zookeeper是什么?我们可以在没有Zookeeper的情况下使用Kafka吗?**

Zookeeper在分布式集群中有广泛的应用，它可以用作 ***数据发布与订阅***、***负载均衡***、***命名服务***、***分布式通知/协调***、***集群管理与Master选举***、***分布式锁***、***分布式队列*** 。

Zookeeper是一个开放源码的、高性能的协调服务，它用于Kafka的分布式应用。

不，不可能越过Zookeeper，直接联系Kafka broker。一旦Zookeeper停止工作，它就不能服务客户端请求。

Zookeeper主要用于在集群中不同节点之间进行通信
在Kafka中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取
除此之外，它还执行其他活动，如: leader检测、分布式同步、配置管理、负载均衡（识别新节点何时离开或连接、集群、节点实时状态）等等。


[zookeeper 在kafka中的作用](https://mp.weixin.qq.com/s?__biz=MzUyMDA4OTY3MQ==&mid=2247487331&amp;idx=1&amp;sn=e945f923cbc79bb19596ea206ac3ecfe&source=41#wechat_redirect)

**7、解释Kafka的用户如何消费信息?**

在Kafka中传递消息是通过使用sendfile API完成的。它支持将字节从套接口转移到磁盘，通过内核空间保存副本，并在内核用户之间调用内核。

消费者消费有各种客户端：

010:http://kafka.apache.org/0102/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html

082 分高阶API和低阶API：

https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example

https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example

**8、解释如何提高远程用户的吞吐量?**

如果用户位于与broker不同的数据中心，则可能需要调优套接口缓冲区大小，以对长网络延迟进行摊销。

**9、解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息?**

在数据中，为了精确地获得Kafka的消息，你必须遵循两件事: 在数据消耗期间避免重复，在数据生产过程中避免重复。

这里有两种方法，可以在数据生成时准确地获得一个语义:

每个分区使用一个单独的写入器，每当你发现一个网络错误，检查该分区中的最后一条消息，以查看您的最后一次写入是否成功
在消息中包含一个主键(UUID或其他)，并在用户中进行反复制

**10、解释如何减少ISR中的扰动?broker什么时候离开ISR?**

ISR是一组与leaders完全同步的消息副本，也就是说ISR中包含了所有提交的消息。ISR应该总是包含所有的副本，直到出现真正的故障。如果一个副本从leader中脱离出来，将会从ISR中删除。

**11、Kafka为什么需要复制?**

Kafka的信息复制确保了任何已发布的消息不会丢失，并且可以在机器错误、程序错误或更常见些的软件升级中使用。

**12、如果副本在ISR中停留了很长时间表明什么?**

如果一个副本在ISR中保留了很长一段时间，那么它就表明，跟踪器可以像在leader收集数据那样快速地获取数据。

**13、请说明如果首选的副本不在ISR中会发生什么?**

如果首选的副本不在ISR中，控制器将无法将leadership转移到首选的副本。

**14、有可能在生产后发生消息偏移吗?**

在大多数队列系统中，作为生产者的类无法做到这一点，它的作用是触发并忘记消息。broker将完成剩下的工作，比如使用id进行适当的元数据处理、偏移量等。

作为消息的用户，你可以从Kafka broker中获得补偿。如果你注视SimpleConsumer类，你会注意到它会获取包括偏移量作为列表的MultiFetchResponse对象。此外，当你对Kafka消息进行迭代时，你会拥有包括偏移量和消息发送的MessageAndOffset对象。

**15、kafka提高吞吐量的配置**

最基础的配置是

batch.size 默认是单批次最大16384字节，超过该值就立即发送。

linger.ms 默认是0ms，超过该时间就立即发送。

上面两个条件满足其一，就立即发送消息否则等待。

**16、kafka支持事务吗？**

0.11版本以后开始支持事务的生产者和消费者。

**17、kafka可以指定时间范围消费吗？**

0.10.2版本以后支持指定时间戳范围消费kafka数据。

**18、新增分区Spark 能发现吗**

Spark Streaming针对kafka0.8.2及以前版本不能进行新增分区及topic发现，0.10以后版本是可以动态检测新增分区和topic。

**19、kafka分区数怎么设定呢？**

一般可以设置为broker或者磁盘的整数倍，然后再结合数据量和后段消费者处理的复杂度及消费者组的数来确定。

**20、kafka的重要监控指标有哪些**

磁盘对与kafka来说比较重要，尽量做矩阵和监控，避免集群故障，而且磁盘问题最容易引起吞吐量下降。

网卡流量，由于副本同步，消费者多导致网路带宽很容易吃紧，所以监控也比较重要。

topic流量波动情况，这个主要是为了后端应对流量尖峰作准备。

消费者lagsize，也即使消费者滞后情况。

**21、Kafka如何保证写入速度**
* 页缓存技术 + 磁盘顺序写
* 零拷贝

**22、Kafka如何做到数据不丢失不重复**

分为三种：

**最多一次（at most once）**: 消息可能丢失也可能被处理，但最多只会被处理一次。


**至少一次（at least once）**: 消息不会丢失，但可能被处理多次。


**精确传递一次（exactly once）**: 消息被处理且只会被处理一次。

**Producer** 生产消息需要需要配置ack参数，有三种设置，分别如下

 * 0： producer完全不管broker的处理结果 回调也就没有用了 并不能保证消息成功发送 但是这种吞吐量最高

*   -1或者all： leader broker会等消息写入 并且ISR都写入后 才会响应，这种只要ISR有副本存活就肯定不会丢失，但吞吐量最低。

 * 1： 默认的值 leader broker自己写入后就响应，不会等待ISR其他的副本写入，只要leader broker存活就不会丢失，即保证了不丢失，也保证了吞吐量。

所以设置为0时，实现了at most once，而且从这边看只要保证集群稳定的情况下，不设置为0，消息不会丢失。

但是还有一种情况就是消息成功写入，而这个时候由于网络问题producer没有收到写入成功的响应，producer就会开启重试的操作，直到网络恢复，消息就发送了多次。这就是at least once了。

kafka producer 的参数acks 的默认值为1，所以默认的producer级别是at least once。并不能exactly once。

**24、Kafka如何保证数据不丢失**

**Kafka如何保障数据不丢失**，即**Kafka的Broker提供了什么机制保证数据不丢失的。**

对于Kafka的Broker而言，Kafka 的**复制机制**和**分区的多副本**架构是Kafka 可靠性保证的核心。把消息写入多个副本可以使Kafka 在发生崩溃时仍能保证消息的持久性。

搞清楚了问题的核心，再来看一下该怎么回答这个问题：主要包括三个方面：

- Topic 副本因子个数：replication.factor >= 3
- 同步副本列表(ISR)：min.insync.replicas = 2
- 禁用unclean选举：unclean.leader.election.enable=false



**24.1 副本因子**

Kafka的topic是可以分区的，并且可以为分区配置多个副本，该配置可以通过`replication.factor`参数实现。

Kafka中的分区副本包括两种类型：领导者副本（Leader Replica）和追随者副本（Follower Replica)，每个分区在创建时都要选举一个副本作为领导者副本，其余的副本自动变为追随者副本。

